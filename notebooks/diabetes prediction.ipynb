{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes Prediction using Pima Indians Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima Indians Diabetes Dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', \n",
    "           'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "data = pd.read_csv(url, header=None, names=columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                # Weighted sum\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                # Step function\n",
    "                y_pred = 1 if linear_output >= 0 else 0\n",
    "                # Update rule\n",
    "                update = self.learning_rate * (y[idx] - y_pred)\n",
    "                self.weights += update * x_i\n",
    "                self.bias += update\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.where(linear_output >= 0, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
      " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
      " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
      " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
      " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
      "(768, 8)\n",
      "[1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0]\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "print(X)\n",
    "print(X.shape)\n",
    "y = data.iloc[:, -1].values   # Target (0 or 1)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(data):\n",
    "    print(f\" Index: {index}, values: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        # Initialize learning rate and number of training epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None \n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, feature_matrix, labels):\n",
    "        # Get the number of samples (rows) and features (columns)\n",
    "        num_samples, num_features = feature_matrix.shape\n",
    "        self.weights = np.zeros(num_features)  # Initialize weights as zeros \n",
    "        self.bias = 0  # Initialize bias as zero\n",
    "        \n",
    "        # Iterate through epochs\n",
    "        for _ in range(self.epochs):\n",
    "            for index, row in enumerate(feature_matrix):\n",
    "                # Compute the linear output\n",
    "                linear_output = np.dot(row, self.weights) + self.bias\n",
    "                # Apply the step function for binary classification\n",
    "                predicted_label = 1 if linear_output >= 0 else 0\n",
    "                \n",
    "                # Calculate the update based on the difference between actual and predicted labels\n",
    "                update = self.learning_rate * (labels[index] - predicted_label)\n",
    "                \n",
    "                # Update weights and bias\n",
    "                self.weights += update * row\n",
    "                self.bias += update\n",
    "\n",
    "\n",
    "    def predict(self, feature_matrix):\n",
    "        # Compute the linear output for the entire feature matrix\n",
    "        linear_output = np.dot(feature_matrix, self.weights) + self.bias\n",
    "        # Apply the step function to produce binary predictions\n",
    "        return np.where(linear_output >= 0, 1, 0)\n",
    "    \n",
    "    def accuracy(self, feature_matrix, labels):\n",
    "        # Predict labels for the feature matrix\n",
    "        predictions = self.predict(feature_matrix)\n",
    "        # Calculate accuracy as the percentage of correct predictions\n",
    "        return np.mean(predictions == labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "perceptron = Perceptron(learning_rate=0.01, epochs=1000)\n",
    "perceptron.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the perceptron\n",
    "predictions = perceptron.predict(X_test)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "accuracy1= perceptron.accuracy(X_test, y_test) #using the function\n",
    "print(\"Perceptron Classification Accuracy on Pima Indians Diabetes Dataset:\", accuracy)\n",
    "print(\"Perceptron Classification Accuracy on Pima Indians Diabetes Dataset: {:.2f}\".format(accuracy1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy as 10 epochs:<br>\n",
    "Perceptron Classification Accuracy on Pima Indians Diabetes Dataset: 0.8181818181818182 <br>\n",
    "Perceptron Classification Accuracy on Pima Indians Diabetes Dataset: 0.82\n",
    "\n",
    "accuracy at 100 epochs: <br>\n",
    "Perceptron Classification Accuracy on Pima Indians Diabetes Dataset: 0.7402597402597403 <br>\n",
    "Perceptron Classification Accuracy on Pima Indians Diabetes Dataset: 0.74\n",
    "\n",
    "accuracy at 1000 epochs: <br>\n",
    "Perceptron Classification Accuracy on Pima Indians Diabetes Dataset: 0.7662337662337663 <br>\n",
    "Perceptron Classification Accuracy on Pima Indians Diabetes Dataset: 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    Dense(1, activation='sigmoid', input_shape=(8,))\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=1000,\n",
    "                   batch_size=32,\n",
    "                   validation_split=0.2,\n",
    "                   verbose=0)\n",
    "\n",
    "# Evaluate\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"\\nTensorFlow Perceptron - Training accuracy: {train_acc:.4f}\")\n",
    "print(f\"TensorFlow Perceptron - Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encoding for the target variable (binary classification)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Define the MLP architecture\n",
    "input_neurons = X.shape[1]\n",
    "hidden_neurons = 64\n",
    "output_neurons = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.randn(input_neurons, hidden_neurons) * 0.01\n",
    "bias_hidden = np.zeros((1, hidden_neurons))\n",
    "weights_hidden_output = np.random.randn(hidden_neurons, output_neurons) * 0.01\n",
    "bias_output = np.zeros((1, output_neurons))\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Training the MLP\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    hidden_layer_input = np.dot(X_train, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_activation = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_activation, weights_hidden_output) + bias_output\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Compute error\n",
    "    error = y_train - predicted_output\n",
    "\n",
    "    # Backpropagation\n",
    "    d_predicted_output = error * sigmoid_derivative(output_layer_input)\n",
    "    error_hidden_layer = np.dot(d_predicted_output, weights_hidden_output.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_input)\n",
    "\n",
    "    # Update weights and biases\n",
    "    weights_hidden_output += np.dot(hidden_layer_activation.T, d_predicted_output) * learning_rate\n",
    "    bias_output += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
    "    weights_input_hidden += np.dot(X_train.T, d_hidden_layer) * learning_rate\n",
    "    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def predict(X):\n",
    "    hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_activation = sigmoid(hidden_layer_input)\n",
    "    output_layer_input = np.dot(hidden_layer_activation, weights_hidden_output) + bias_output\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "    return (predicted_output > 0.5).astype(int)\n",
    "\n",
    "train_accuracy = np.mean(predict(X_train) == y_train)\n",
    "test_accuracy = np.mean(predict(X_test) == y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with 2 Hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Outcome']).values\n",
    "y = data['Outcome'].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encoding for the target variable (binary classification)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Define the MLP architecture\n",
    "input_neurons = X.shape[1]\n",
    "hidden_neurons_1 = 64\n",
    "hidden_neurons_2 = 32\n",
    "output_neurons = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)\n",
    "weights_input_hidden1 = np.random.randn(input_neurons, hidden_neurons_1) * 0.01\n",
    "bias_hidden1 = np.zeros((1, hidden_neurons_1))\n",
    "weights_hidden1_hidden2 = np.random.randn(hidden_neurons_1, hidden_neurons_2) * 0.01\n",
    "bias_hidden2 = np.zeros((1, hidden_neurons_2))\n",
    "weights_hidden_output = np.random.randn(hidden_neurons_2, output_neurons) * 0.01\n",
    "bias_output = np.zeros((1, output_neurons))\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Training the MLP\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    hidden_layer1_input = np.dot(X_train, weights_input_hidden1) + bias_hidden1\n",
    "    hidden_layer1_activation = sigmoid(hidden_layer1_input)\n",
    "\n",
    "    hidden_layer2_input = np.dot(hidden_layer1_activation, weights_hidden1_hidden2) + bias_hidden2\n",
    "    hidden_layer2_activation = sigmoid(hidden_layer2_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer2_activation, weights_hidden_output) + bias_output\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Compute error\n",
    "    error = y_train - predicted_output\n",
    "\n",
    "    # Backpropagation\n",
    "    d_predicted_output = error * sigmoid_derivative(output_layer_input)\n",
    "    error_hidden_layer2 = np.dot(d_predicted_output, weights_hidden_output.T)\n",
    "    d_hidden_layer2 = error_hidden_layer2 * sigmoid_derivative(hidden_layer2_input)\n",
    "\n",
    "    error_hidden_layer1 = np.dot(d_hidden_layer2, weights_hidden1_hidden2.T)\n",
    "    d_hidden_layer1 = error_hidden_layer1 * sigmoid_derivative(hidden_layer1_input)\n",
    "\n",
    "    # Update weights and biases\n",
    "    weights_hidden_output += np.dot(hidden_layer2_activation.T, d_predicted_output) * learning_rate\n",
    "    bias_output += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    weights_hidden1_hidden2 += np.dot(hidden_layer1_activation.T, d_hidden_layer2) * learning_rate\n",
    "    bias_hidden2 += np.sum(d_hidden_layer2, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    weights_input_hidden1 += np.dot(X_train.T, d_hidden_layer1) * learning_rate\n",
    "    bias_hidden1 += np.sum(d_hidden_layer1, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def predict(X):\n",
    "    hidden_layer1_input = np.dot(X, weights_input_hidden1) + bias_hidden1\n",
    "    hidden_layer1_activation = sigmoid(hidden_layer1_input)\n",
    "\n",
    "    hidden_layer2_input = np.dot(hidden_layer1_activation, weights_hidden1_hidden2) + bias_hidden2\n",
    "    hidden_layer2_activation = sigmoid(hidden_layer2_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer2_activation, weights_hidden_output) + bias_output\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "    return (predicted_output > 0.5).astype(int)\n",
    "\n",
    "train_accuracy = np.mean(predict(X_train) == y_train)\n",
    "test_accuracy = np.mean(predict(X_test) == y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(columns=['Outcome']).values\n",
    "y = data['Outcome'].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the MLP model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Hidden layer 1\n",
    "    Dense(32, activation='relu'),  # Hidden layer 2\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
